{"componentChunkName":"component---src-templates-blog-post-js","path":"/p/ultimate-off-heap-hash-set-using-redis/","result":{"data":{"markdownRemark":{"id":"80dabf73-b7fb-5838-853a-ad30e6596e21","excerpt":"After my post about making off-heap Set-like data structure, my friend threw an idea at me: why not to go all the way, and use not just off-heap, but off…","html":"<p>After my <a href=\"/p/replacing-hash-set-with-sorted-array-in-java\">post</a> about making off-heap Set-like data structure, my friend threw an idea at me: why not to go all the way, and use not just off-heap, but off-process? Why not to try to use <a href=\"https://redis.io/\">Redis</a> as a side-car and have caches there?</p>\n<p>Indeed, why not to try?</p>\n<p>I must say, that I knew in advance, that it’s impossible for this solution to be faster than in-process cache, but it was still interesting, how slower it would be. And here we are, benchmarking <a href=\"https://redis.io/docs/data-types/#sets\">Redis Set</a>.</p>\n<h2 id=\"what-are-we-testing\" style=\"position:relative;\"><a href=\"#what-are-we-testing\" aria-label=\"what are we testing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>What are we testing?</h2>\n<p>My use case is simple - I have a large in-memory set of <a href=\"https://cr.openjdk.java.net/~iris/se/17/latestSpec/api/java.base/java/util/UUID.html\">UUID</a>, around 1 million keys. For the benchmark sake I created 3 sets in Redis: 100K, 1M and 10M elements. Allegedly, the size of the Set shouldn’t affect performance.</p>\n<p>I went the simplest path by running Redis in a <a href=\"https://hub.docker.com/_/redis\">docker container</a>:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">docker</span> run --name my-redis -p <span class=\"token number\">6379</span>:6379 redis:7.0-alpine</code></pre></div>\n<p>Next step is to generate data. I wanted to do it in bash, but <code class=\"language-text\">uuidgen</code> takes few milliseconds and to generate even 100K UUIDs takes to much time. Spawning a process is an expensive operation. A small script in Java to generate 100K UUIDs take less than a second.</p>\n<p>Then I wrote a simple <a href=\"https://github.com/dkomanov/stuff/blob/master/src/com/komanov/redis/bin/DataFiller.scala\">script</a> to fill Redis with data. I use <a href=\"https://lettuce.io/\">Lettuce</a> — a Java client for Redis. For that I need to provide a codec for the library to know how to encode/decode keys and values. <a href=\"https://github.com/dkomanov/stuff/blob/master/src/com/komanov/redis/StringUuidCodec.scala\">Codec</a> for UUID is pretty simple, I encode it as 16 bytes:</p>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">override</span> <span class=\"token keyword\">def</span> encodeValue<span class=\"token punctuation\">(</span>value<span class=\"token operator\">:</span> UUID<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> ByteBuffer <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">val</span> bb <span class=\"token operator\">=</span> ByteBuffer<span class=\"token punctuation\">.</span>allocate<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">)</span>\n  bb<span class=\"token punctuation\">.</span>putLong<span class=\"token punctuation\">(</span>value<span class=\"token punctuation\">.</span>getMostSignificantBits<span class=\"token punctuation\">)</span>\n  bb<span class=\"token punctuation\">.</span>putLong<span class=\"token punctuation\">(</span>value<span class=\"token punctuation\">.</span>getLeastSignificantBits<span class=\"token punctuation\">)</span>\n  bb<span class=\"token punctuation\">.</span>rewind<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  bb\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2 id=\"benchmark\" style=\"position:relative;\"><a href=\"#benchmark\" aria-label=\"benchmark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Benchmark</h2>\n<p>For benchmarking I use <a href=\"https://github.com/lettuce-io/lettuce-core/wiki/Asynchronous-API\">async API</a> to deal as less as possible with multiple threads. Because Redis is single-threaded, it’s <a href=\"https://github.com/lettuce-io/lettuce-core/wiki/Connection-Pooling\">advised</a> to use a single connection, which I did.</p>\n<p>The <a href=\"https://github.com/dkomanov/stuff/blob/master/src/com/komanov/redis/perf/PerfTester.java\">benchmark code</a> is a little bit complicated. I test for different parallelism — amount of concurrent requests to Redis, calculate duration by myself (it’s not easy to utilize JMH for such use case without using blocking API).</p>\n<p>I don’t think my benchmark is very clever, for simplicity I use <a href=\"https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/LinkedBlockingDeque.html\">LinkedBlockingDeque</a> in a main thread, and I use <code class=\"language-text\">remove</code> method, which is <code class=\"language-text\">O(N)</code> as it iterates over entire deque. However, I don’t think it affects benchmark, request duration doesn’t include it anyway.</p>\n<h2 id=\"results\" style=\"position:relative;\"><a href=\"#results\" aria-label=\"results permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Results</h2>\n<p>All results available in <a href=\"https://docs.google.com/spreadsheets/d/1D5fhP-rxuxamOl58cGk7yLiLiViZnxWcE71klp6JC3I\">Google Sheets</a>. As I mentioned, the performance doesn’t really depend on a set size. From now on I’m going to use graphs and numbers for the benchmark of a set with 1M keys.</p>\n<p>Here is a graph of a median request duration for different parallelism (from 1 to 100, step 10) and total test duration:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4362d3041704c06385fce14dc62b28cf/fcda8/set-1m.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 78.91891891891892%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAACFklEQVQ4y41T267jIBDL///mtqdJgFwJd+KVJ6Xb9rws0ogBhPF4THccBxjWWmzbBu+95M45yRn7viOEgJwzUkqv4Po7Ol4chgG3203CTBPGcYDWGsuyYF1XOQ8x4n9GV2v9tXlEYJoJ1OPR9/CHxbkuuP/8YBxHPB4PzPP86955nuhKKWAopYRyLQUxZcSYEGOEZ6kpocQoZce3uZ4nUoy43++yFoYE46j1lBeuvH7k7fV/eQWzk1pORoBJhqBdu2yMQSHDWl8C8zGKz71Xzsu1IlmLrAZE55BLkUZS6+6iHxBiRi6fDBmlsapVwE7vUbRCngypijzLPItTqG9HZkZrOB+h1yQgOV+6XmyvPcKmeUIxWiopzweaZLTXNE3o6D3ag7qoNV+sCPYELGSVE7JWSEaDNRCMoGTIColB+5Fcx/YTmfqYLUnZ7wzSPKOoEcU5lGfjmjPOJyD1Y/R9f5VME+ccsR4Z1lecOFFoFz0iLbOwap18B2zN4iBDWq+7fsPGK9j9CZd5aoUVckJ9mbai1vKWXydkyApfgHyVY983BOeh/mh4pRFTRSosKSHlipiKOOE753l5t02jLN2dDfbFQu1VOt7CbFlmJesM/VwzX/Z0fdfjEOm697bv9oDzDloN2NYFx7FjHHq4w8qaefAORisYoxGCw/1+k3I//vL38D7IV2xiN7O3PISImC5mu7XikAb4FyYv4IcEM9OMAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Median request duration by parallelism, microseconds\"\n        title=\"Median request duration by parallelism, microseconds\"\n        src=\"/static/4362d3041704c06385fce14dc62b28cf/fcda8/set-1m.png\"\n        srcset=\"/static/4362d3041704c06385fce14dc62b28cf/1d79a/set-1m.png 185w,\n/static/4362d3041704c06385fce14dc62b28cf/1efb2/set-1m.png 370w,\n/static/4362d3041704c06385fce14dc62b28cf/fcda8/set-1m.png 590w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Minimal median duration is 74 microseconds (vs 100 nanoseconds for lookup in <a href=\"https://cr.openjdk.java.net/~iris/se/17/latestSpec/api/java.base/java/util/HashSet.html\">HashSet</a>), the fastest requests was 47 microseconds. The slowest was 19 millis, but it was a single request, other slowest requests were under 7 millis (which is still a lot). But keep in mind that Redis was under 100% utilization in this benchmark, it’s unlikely to load Redis as much if Redis is a side-car… nevermind :)</p>\n<p>The median increases with the parallelism (which makes sense). However, single-threaded parallelism doesn’t utilize Redis 100%. There’s some sweet-spot between duration and throughput, but hard to tell exactly where, depends on the application needs, I guess.</p>\n<p>If we take a look for higher parallelism (from 1 to 1000), we’ll see that request duration skyrockets after 100 simultaneous requests (even before):</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/3800027d70066c2946809efd0472bc60/fcda8/set-1m-all.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 78.91891891891892%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAACFklEQVQ4y41Ua4+bMBDk///Eqh9OOe7AYJ4x8dtTzQYnvUSVammEvdjDzO6a5jgOEMYY7PsOa63Mb7ebzInr9SqxGCNCCA9w/YqGB5VSaNtWMM0zhkFh0hrrumLbNvRKSfx/RpNzfgseHpiXDUr16Loe9jAo+4av728Mw4Cu67Asy9u5UgqalBIIbqSNnBJ8IAKccwLGk/ePtfdeQAKm6+PjQ/aIQpJx8PlUWwSv6knwd6zkjLCuEmP++BGxzI1aa8QY5GVVLcrOeT1E0EUqQDJXWD0ipCRFYy2aasH5AOvzqeRdzavCIsk2MFpjnCaxzrQ10zSJOu8d1OLhQqaXhyI+K6j0ESsFUQ9im4PdMs8zGvbeum7ImYWI0PuTgIerqvokqcyZnnWGOQ4hIiGFNSw/A7SeYsDhMhbDr/5bIe2mfUM2Boe10qvMYd/3d8tEbQ9mZzZZiHN+Eoqqs0CcJz3Kmtar5XEc0fA20HatZk0+rceYHi3ESpWS76ttQTmM7L3uu1SXhFIUWuCg7HDaIYENBWqLiKkgEAXwKeM2avh5QcxATBnOe0nDo22qKtoK1iKeSM7C7Af0bKGHHcPniOlTYewWTCZj2gL0HnG4uyC2jRQlnQr5R5k/L7h+tdi/WmxtC/X7F/b2AqM63LYFWvUY9Qh7u/+d6OpyuUgf/7jLVWF5uewuhB8x65z8zurgmfW8epXwDw2a4CpNRz47AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Median request duration by parallelism till 1000, microsecond\"\n        title=\"Median request duration by parallelism till 1000, microsecond\"\n        src=\"/static/3800027d70066c2946809efd0472bc60/fcda8/set-1m-all.png\"\n        srcset=\"/static/3800027d70066c2946809efd0472bc60/1d79a/set-1m-all.png 185w,\n/static/3800027d70066c2946809efd0472bc60/1efb2/set-1m-all.png 370w,\n/static/3800027d70066c2946809efd0472bc60/fcda8/set-1m-all.png 590w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h2 id=\"i-got-it-wrong\" style=\"position:relative;\"><a href=\"#i-got-it-wrong\" aria-label=\"i got it wrong permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>I Got It Wrong</h2>\n<p>When I wrote a sentence about CPU utilization in Redis, I suddenly remembered that when I ran benchmarks I saw not only <code class=\"language-text\">docker redis</code> process with 100% CPU load, but also <code class=\"language-text\">docker-proxy</code> process. Back then I thought: “Huh!” But now I remembered it and decided to make yet another benchmark: I installed <code class=\"language-text\">redis-server</code> (apparently it’s even simpler than running a docker on Ubuntu) and ran benchmarks, but not all, just for parallelism from 1 to 10.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 591px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d64c22d1870a0e2f03ecf8180d91e373/e4c9a/compare-median.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 78.91891891891892%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAACAUlEQVQ4y31Uia7jMAjM/3/oto1zOJfjAzyrIXHb97RaJATYDh5gnC6EgOM4TM/zNKXPdeq+79i2zXzutfNtv/mlFOSc0XHh8Xjg+XzCe495ni3uncPj8Qev59NiNwyWfJomDMOAZVngnDNd1xVNOlVFrdU2RASMVStUBSkrjnAixQiN0ZBG+qpfZ/VH3NGhEHJbFFFUFWynoh89tsWj+Bmv18uQEYCdFTErBAWY/07YkDZlDDt2ieIj9U7QVGJETRFSCjreOI6jaUrJkH4rG/2OVVFuRDkE5HlCHhzSNCJPI0o40HEI7B9uyN99USK90UnO0GO30mVwKPMECcHKbpXQ7zhZomtlMwm3LVnJkG2FTAPK6CDrAgnHu+T2zX4K1qA4k6Dj5EgForSSc0JeFyslux7JzygxWqm8Sus1iJgy/J7R+4JpzdhCQWYPWzKb9DyhDA6yb9Ccv0YCm3yICn8Ixk0xboIjXoxA1RvtXTKTXtP9TLZIRSmKNQimXeCWqyyWZ7SqV6LGwUaljuj6vje2j8uJaSsY1wy3FAxrwXpknJEcLYZA5fJ/M4HJ6Hd8h2Q/JZWKM1ezHw7eE6yXrV/2W9uAuovAuG/LkFt5KzWlj9/Q/EvbS+voUPjw28/B++W2/m3ZZz6CZrne9kg7tozxf5/eb9vI/5n8ZxgU/t7+AiPr4e12fXEzAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Comparison of median request duration: docker vs local\"\n        title=\"Comparison of median request duration: docker vs local\"\n        src=\"/static/d64c22d1870a0e2f03ecf8180d91e373/e4c9a/compare-median.png\"\n        srcset=\"/static/d64c22d1870a0e2f03ecf8180d91e373/1d79a/compare-median.png 185w,\n/static/d64c22d1870a0e2f03ecf8180d91e373/1efb2/compare-median.png 370w,\n/static/d64c22d1870a0e2f03ecf8180d91e373/e4c9a/compare-median.png 591w\"\n        sizes=\"(max-width: 591px) 100vw, 591px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Yes, this is the difference between local Redis vs dockerized Redis. Local Redis is almost two times faster o_O Yup.</p>\n<h2 id=\"extra-memory-usage\" style=\"position:relative;\"><a href=\"#extra-memory-usage\" aria-label=\"extra memory usage permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Extra (Memory Usage)</h2>\n<p>The last bit I decided to check - what’s the memory consumption? Redis has a very convenient command <a href=\"https://redis.io/commands/memory-usage/\">MEMORY USAGE</a> which returns how much memory it takes to hold a key in memory:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">127.0.0.1:6379> MEMORY USAGE set-1m SAMPLES 0\n(integer) 56388712\n127.0.0.1:6379> MEMORY USAGE set-10m SAMPLES 0\n(integer) 614217840\n127.0.0.1:6379> MEMORY USAGE set-100k SAMPLES 0\n(integer) 5848688</code></pre></div>\n<p>UUID’s size is fixed 16 bytes and Redis takes 56-61 bytes per value. The reason is described <a href=\"https://redis.io/commands/memory-usage/\">here</a>: basically, jemalloc allocates pages, and the smallest page size is bigger than our small value (51 bytes in example in docs). So, basically, Redis uses more or less the same amount of memory as <code class=\"language-text\">java.util.HashSet</code>. Okay.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>An obvious conclusion is that going Out-Of-Process is much more expensive than going Off-Heap in JVM (50-100-1000 times slower). But when I benchmarked against locally installed <code class=\"language-text\">redis-server</code>, the difference was around 50x times, which is still huge, but not “that huge”. Would I consider it? Probably not, not for my particular use case. But who knows, maybe such solution some time will help and simplify something :)</p>\n<p>Parallelism for single-threaded app is an interesting thing, I should’ve benchmarked multiple connections, probably, but I’m a bit lazy as I spent on this benchmark more than I wanted to.</p>\n<p>About the cover image: redis means radish in Russian, so, why not? :) Especially, there’s desktop client for Redis called Radish (I don’t know if it’s any good.)</p>\n<p>Full data and <a href=\"https://docs.google.com/spreadsheets/d/1D5fhP-rxuxamOl58cGk7yLiLiViZnxWcE71klp6JC3I\">charts</a>. Source code is on <a href=\"https://github.com/dkomanov/stuff/commit/30101587ec9ecaddcf0e0f706f4565b22e3d5739\">GitHub</a>. Originally posted on <a href=\"https://dkomanov.medium.com/ultimate-off-heap-hash-set-using-redis-53f9d4e11aae\">Medium</a>. <a href=\"https://pixabay.com/photos/agriculture-radish-food-1870017/\">Cover image</a> by <a href=\"https://pixabay.com/users/pexels-2286921/\">Pexels</a> from <a href=\"https://pixabay.com/\">Pixabay</a>.</p>","fields":{"slug":"/p/ultimate-off-heap-hash-set-using-redis/"},"frontmatter":{"rawDate":"2022-08-31T00:00:00.000Z","date":"August 31, 2022","title":"Ultimate Off-Heap Hash Set: Using Redis","description":"A benchmark to check the performance of out-of-process cache in Redis to potentially replace in-process cache","tags":["java","redis","benchmark","performance"],"canonicalUrl":"https://dkomanov.medium.com/ultimate-off-heap-hash-set-using-redis-53f9d4e11aae","cover":{"publicURL":"/static/f838920412145ad3e355db3a82110c76/cover.jpg"}}}},"pageContext":{"slug":"/p/ultimate-off-heap-hash-set-using-redis/","previous":{"fields":{"slug":"/p/replacing-hash-set-with-sorted-array-in-java/"}},"next":{"fields":{"slug":"/p/mysql-as-redis-vs-redis/"}}}},"staticQueryHashes":["3675711862"]}